---
title: 语音方向的基础概念
date: 2022-05-04 10:02:00
---





## 声音特性[^1]

**声音**（sound)是由物体振动产生的声波。是通过介质传播并能被人或动物听觉器官所感知的波动现象。最初发出振动的物体叫声源。声音以波的形式振动传播。声音是声波通过任何介质传播形成的运动。

**频率**：是每秒经过一给定点的**声波**数量，它的测量单位为赫兹，1千赫或1000赫表示每秒经过一给定点的声波有1000个周期，1兆赫就是每秒钟有1,000,000个周期，等等。

**音节**：就是听觉能够自然察觉到的最小语音单位，音节有声母、韵母、声调三部分组成。一个汉字的读音就是一个音节，一个英文单词可能有一个或多个音节构成，并且按照音节的不同，可以分为不同的种类。

**音素**：它是从音节中分析出来的最小语音单位，语音分析到音素就不能再分了。比如，“她穿红衣服”是5个音节，而“红”又可进一步分为3个音素--h,o,ng。音素的分析需要一定的语音知识，但是，如果我们读的慢一点是还可以体会到的。

对于英语而言，一种常用的音素信息是卡内基梅隆大学的一套由39个因素构成的[音素集](https://link.zhihu.com/?target=http%3A//www.speech.cs.cmu.edu/cgi-bin/cmudict)。汉语一般直接用全部声母和韵母作为音素集，另外汉语识别还分为有调和无调。

**状态**可以理解为比音素更加细致的语音单位，通常把一个音素划分为3个状态。

**音位**：是指能够区分意义的音素，比如bian,pian,bu,pu就是靠b，p两个音素来区分的，所以b，p就是两个音位。

人耳能听到的音频范围：20HZ--20KHZ。人说话的声音频率：300HZ--3.4KHZ。乐器的音频范围：20HZ--20KHZ。



## 语音时域特性

语音信号有时变特性，是一个非平稳的随机过程。但在一个短时间范围内其特性基本 保持不变，即语音的“短时平稳性”。

在时域，语音信号可以直接用它的时间波形表示出来。其中，清音段类似于白噪声，具有较高的频率，但振幅很小，没有明显的周期性；而浊音都具有明显的周期性，且幅值较大，频率相对较低。语音信号的这些时域特征可以通过**短时能量**、**短时过零率**等方法来分析。

### 短时能量

由于语音信号的能量随时间而变化，清音和浊音之间的能量差别相当显著。因此，对短时能量和短时平均幅度进行分析，可以描述语音的这种特征变化情况。

定义n时刻某语音信号的短时平均能量为：
$$
E_n = \sum^{+\infty}_{m = -\infty}{[x(m) w (n-m)]^2} = \sum^{n}_{m=n-(N-1)}{[x(m) w (n-m)]^2}
$$
N为窗长，可见短时能量为一帧样点值的加权平方和。特殊地，当窗函数为矩形窗时，有
$$
E_n = \sum^{n}_{m=n-(N-1)}{x^2(m)}
$$


### 短时幅度

短时能量的一个主要问题是对信号电平值过于敏感。由于需要计算信号样值的平方和，在定点实现时很容易产生溢出。为了克服这个缺点，可以定义一个短时平均幅度函数来衡量语音幅度的变化：
$$
M_n = \sum^{+\infty}_{m=-\infty}{|x(m)|w(n-m)} = \sum^{n}_{m=n-N+1}{|x(n)|w(n-m)}
$$
上式可以理解为w(n)对|x(n)|的线性滤波运算，实现框图如下。与短时能量比较，短时平均幅度相当于用绝对值之后代替了平方和，简化了运算。

### 短时过零率

短时平均过零率是语音信号时域分析中的一种特征参数。它是指每帧内信号通过零值的次数。

①对有时间横轴的连续语音信号，可以观察到语音的时域波形通过横轴的情况。

②在离散时间语音信号情况下，如果相邻的采样具有不同的代数符号就称为发生了过零，因此可以计算过零的次数。

单位时间内过零的次数就称为过零率。一段长时间内的过零率称为平均过零率。如果是正弦信号，其平均过零率就是信号频率的两倍除以采样频率，而采样频率是固定的。因此过零率在一定程度上可以反映信号的频率信息。短时平均过零率的定义为：

![img](https://raw.githubusercontent.com/Moriarty12138/PictureBed/main/img/202205041504133.jpeg)

![img](https://raw.githubusercontent.com/Moriarty12138/PictureBed/main/img/202205041504742.png)

## 语音的频域特征

### 信号分类

计算信号能量（作用在单位电阻上的电压信号 释放的能量）可以将信号分为：

* 功率信号：能量无限，不能用能量表示，所以用平均功率表示；

* 能量信号：能量有限，平均功率为0；

![img](https://raw.githubusercontent.com/Moriarty12138/PictureBed/main/img/202205041505650.jpeg)

### 频谱

功率信号的频谱（离散）：

![img](https://raw.githubusercontent.com/Moriarty12138/PictureBed/main/img/202205041506219.png)

含义： 周期功率信号幅值（频率为f0）经过傅里叶级数展开，被多个离散倍频nf0表征，各频点的幅值C(nf0)也即该频点的贡献权系数。



### 功率谱密度

功率信号的功率谱密度（连续）:

![image-20220504150837989](https://raw.githubusercontent.com/Moriarty12138/PictureBed/main/img/202205041508041.png)

含义：

* 将信号的功率按照频点贡献铺在频谱之上；

* 因其能量是无穷的，所以不能把能量铺上去，只能用有限的功率；

* 对功率谱密度进行积分，能得到局部频段承载的功率；

* 相比功率信号的频谱突出各频点对功率信号的信号幅值的贡献，功率谱密度突出各频点对功率信号的功率的贡献。



### 频谱密度

能量信号的频谱密度（连续）：

![image-20220504151026370](https://raw.githubusercontent.com/Moriarty12138/PictureBed/main/img/202205041510405.png)

含义：

* 通过傅里叶变换将能量信号转换到连续频域上；

* 但因能量有限，不能使用离散贡献频点权系数（几乎为0），只能使用频谱密度来表征。



### 能量谱密度

能量信号的能量谱密度（连续）：

![image-20220504151125842](https://raw.githubusercontent.com/Moriarty12138/PictureBed/main/img/202205041511893.png)

含义：

* 将信号能量铺在频谱之上；

* 对能量谱密度进行局部积分，能得到局部频段承载的能量；

* 相比能量信号的频谱密度突出连续频点对功率信号的信号幅值的贡献，能量谱密度突出连续频点对能量信号的能量的贡献。





## 语音识别（ASR）过程

![img](https://pic4.zhimg.com/80/v2-b4a2539897f4299303b50dbe1070480f_720w.jpg)

所谓语音识别，就是将一段语音信号转换成相对应的文本信息，系统主要包含**特征提取**、**声学模型**、**语言模型**以及**字典**与**解码**四大部分，此外为了更有效地提取特征往往还需要对所采集到的声音信号进行**滤波**、**分帧**等音频数据预处理工作，将需要分析的音频信号从原始信号中合适地提取出来；特征提取工作将声音信号从时域转换到频域，为声学模型提供合适的特征向量；声学模型中再根据声学特性计算每一个特征向量在声学特征上的得分；而语言模型则根据语言学相关的理论，计算该声音信号对应可能词组序列的概率；最后根据已有的字典，对词组序列进行解码，得到最后可能的文本表示[^1]。

补充概念：

### **音频信号预处理**：

音频信号的预处理包括：（1）首尾端的静音切除（VAD），降低对后续步骤的干扰；（2）声音分帧，将声音进行切分，一段称为一帧。使用移动窗函数实现，不是简单的切分，每帧之间包含一定重叠。 

#### 滤波[^2]

[滤波](https://www.google.com.hk/search?q=%E6%BB%A4%E6%B3%A2&newwindow=1&rlz=1C1GCEU_zh-CNUS937US937&ei=TR1yYuvgGZCI0gSO_KrwCQ&ved=0ahUKEwiru_r8m8X3AhUQhJQKHQ6-Cp4Q4dUDCA4&uact=5&oq=%E6%BB%A4%E6%B3%A2&gs_lcp=Cgdnd3Mtd2l6EAMyBggAEAcQHjIGCAAQBxAeMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB4yBggAEAcQHkoECEEYAEoECEYYAFAAWABgxgFoAHAAeACAAYcBiAGHAZIBAzAuMZgBAKABAcABAQ&sclient=gws-wiz)（Wave filtering）是将信号中特定波段频率滤除的操作，是抑制和防止干扰的一项重要措施，滤波分为经典滤波和现代滤波。



#### 分帧[^3]

语音信号处理常常要达到的一个目标，就是弄清楚语音中**各个频率成分的分布**。做这件事情的数学工具是**[傅里叶变换](https://www.zhihu.com/search?q=傅里叶变换&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A225983811})**。傅里叶变换要求输入信号是**平稳**的，当然不平稳的信号你想硬做也可以，但得到的结果就没有什么意义了。而语音在宏观上来看是不平稳的——你的嘴巴一动，信号的特征就变了。但是从微观上来看，在比较短的时间内，嘴巴动得是没有那么快的，语音信号就可以看成平稳的，就可以截取出来做傅里叶变换了。这就是为什么语音信号要分帧处理，截取出来的一小段信号就叫一「帧」。

如下图：这段语音的前三分之一和后三分之二明显不一样，所以整体来看语音信号不平稳。红框框出来的部分是一帧，在这一帧内部的信号可以看成平稳的。

![img](https://raw.githubusercontent.com/Moriarty12138/PictureBed/main/img/202205041442582.png)

那么一帧有多长呢？帧长要满足两个条件：

- 从宏观上看，它必须足够短来保证帧内信号是平稳的。前面说过，口型的变化是导致信号不平稳的原因，所以在一帧的期间内口型不能有明显变化，即一帧的长度应当小于一个**音素**的长度。正常语速下，音素的持续时间大约是 50~200 毫秒，所以帧长一般取为小于 50 毫秒。
- 从微观上来看，它又必须包括足够多的振动周期，因为傅里叶变换是要分析频率的，只有重复足够多次才能分析频率。语音的[基频](https://www.zhihu.com/search?q=基频&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A225983811})，男声在 100 赫兹左右，女声在 200 赫兹左右，换算成周期就是 10 毫秒和 5 毫秒。既然一帧要包含多个周期，所以一般取至少 20 毫秒。

这样，我们就知道了帧长一般取为 20 ~ 50 毫秒，20、25、30、40、50 都是比较常用的数值，甚至还有人用 32。

取出来的一帧信号，在做傅里叶变换之前，要先进行「**加窗**」的操作，即与一个「窗函数」相乘，如下图所示：

![img](https://raw.githubusercontent.com/Moriarty12138/PictureBed/main/img/202205041444700.png)

加窗的目的是让一帧信号的幅度在两端**渐变**到 0。渐变对傅里叶变换有好处，可以让频谱上的各个峰更细，不容易糊在一起（术语叫做**减轻频谱泄漏**），具体的数学就不讲了。

加窗的代价是一帧信号两端的部分被削弱了，没有像中央的部分那样得到重视。弥补的办法是，帧不要背靠背地截取，而是相互重叠一部分。相邻两帧的起始位置的时间差叫做**帧移**，常见的取法是取为**帧长的一半**，或者固定取为 **10 毫秒**。

对一帧信号做傅里叶变换，得到的结果叫**频谱**，它就是下图中的蓝线：

![img](https://raw.githubusercontent.com/Moriarty12138/PictureBed/main/img/202205041445788.png)

图中的横轴是频率，纵轴是幅度。频谱上就能看出这帧语音在 480 和 580 赫兹附近的能量比较强。语音的频谱，常常呈现出「精细结构」和「[包络](https://www.zhihu.com/search?q=包络&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A225983811})」两种模式。「精细结构」就是蓝线上的一个个小峰，它们在横轴上的间距就是**基频**，它体现了语音的**音高**——峰越稀疏，基频越高，音高也越高。「包络」则是连接这些小峰峰顶的平滑曲线（红线），它代表了口型，即发的是哪个音。包络上的峰叫**共振峰**，图中能看出四个，分别在 500、1700、2450、3800 赫兹附近。有经验的人，根据共振峰的位置，就能看出发的是什么音。

对每一帧信号都做这样的傅里叶变换，就可以知道音高和口型随时间的变化情况，也就能识别出一句话说的是什么了。



### **特征提取**

主要算法有**线性预测倒谱系数（LPCC）**和**Mel 倒谱系数（MFCC）**，目的是把每一帧波形变成一个包含声音信息的多维向量。



过去在语音识别上所取得成果证明 MFCC 是一种行之有效的特征提取方法。但随着深度学习的发展，受限的玻尔兹曼机（RBM）、卷积神经网络（CNN）、CNN-LSTM-DNN（CLDNN）等深度神经网络模型作为一个直接学习滤波器代替梅尔滤波器组被用于自动学习的语音特征提取中，并取得良好的效果[^4]。



### **声学模型**：

声学模型通过对语音数据进行训练获得，输入是特征向量，输出为音素信息。



在深度学习兴起之前，混合高斯模型（GMM）和隐马尔可夫模型（HMM）一直作为非常有效的声学模型而被广泛使用，当然即使是在深度学习高速发展的今天，这些传统的声学模型在语音识别领域仍然有着一席之地[^4]。

### **语言模型**：

字典：字或者词与音素的对应， 简单来说， 中文就是拼音和汉字的对应，英文就是音标与单词的对应。

语言模型（LM）：通过对大量文本信息进行训练，得到单个字或者词相互关联的概率。

### **解码**：

解码就是通过声学模型，字典，语言模型对提取特征后的音频数据进行文字输出。



## 端到端语音识别

无论是 GMM 和 HMM 这样的传统声学模型，还是基于深度学习的声学模型，它们对于整个语音识别系统都是分开优化的，但是语音识别本质上是一个序列识别问题，如果模型中的所有组件都能够联合优化，很可能会获取更好的识别准确度，所以我们需要一种端到端（End2End）的语音识别处理系统[^4]。



## 参考资料

[^1]:[AI大语音（一）| 语音识别基础（深度解析）](https://zhuanlan.zhihu.com/p/176820760)
[^2]:[分帧，加窗和DFT](https://zhuanlan.zhihu.com/p/397643730)
[^3]:[语音信号处理中怎么理解分帧？](https://www.zhihu.com/question/52093104)
[^4]:[深度学习笔记 | 第16讲：语音识别——一份简短的技术综述](https://zhuanlan.zhihu.com/p/53264756)

