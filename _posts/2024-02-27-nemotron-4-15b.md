---
title: 技术报告 Nemotron-4 15B
date: 2024-02-27 15-32-05
---




arxiv：https://arxiv.org/abs/2402.16819



作者对比了 Qwen 14B 、Nemotron-4 15B 、Mistral 7B 、Gemma 7B 、LLaMA-2 34B 。

<img src="https://gqjia-images-1254146217.cos.ap-nanjing.myqcloud.com/gqjia-post202402271428060.png" alt="image-20240227142821969" style="zoom:50%;" />

Nemotron-4 15B 优于 LLaMA-2 34B ，在英语任务上优于 Mistral 7B ，与  Qwen 14B  和 Gemma 7B 相当。

（这张图难道不是说明 Gemma 7B 的强大嘛。

在多语言任务上，Nemotron-4 15B 优于其他模型。





模型超参数设置：

<img src="https://gqjia-images-1254146217.cos.ap-nanjing.myqcloud.com/gqjia-post202402271441471.png" alt="image-20240227144119434" style="zoom:50%;" />

在模型结构上：

1.   RoPE 位置编码
2.   SentencePiece tokenizer
3.   MLP 层使用 ReLU 激活函数，没有 bias， dropout 0，untied input-output embeddings
4.   GQA



数据上：

训练数据包括 8T token 的多语言数据，其中 英语数据 70%、多语言数据 15%、代码数据 15%。

数据配比如下：

<img src="https://gqjia-images-1254146217.cos.ap-nanjing.myqcloud.com/gqjia-post202402271447681.png" alt="image-20240227144703646" style="zoom:50%;" />

代码数据中各语言占比如下：

<img src="https://gqjia-images-1254146217.cos.ap-nanjing.myqcloud.com/gqjia-post202402271449677.png" alt="image-20240227144909655" style="zoom:50%;" />

多语言数据各语言占比如下：

<img src="https://gqjia-images-1254146217.cos.ap-nanjing.myqcloud.com/gqjia-post202402271449783.png" alt="image-20240227144944759" style="zoom:50%;" />



在数据清洗上，作者做了文档级别的精确和近似去重。除此之外还使用语言模型等对文档做了去重。

在tokenizer 上， 从 8T 数据中随机抽出一部分数据，使用 SentencePiece 训练一个 tokenizer 。训练数据中对非英语数据做了上采样。tokenizer 保留空格，将 数字 进一步拆分，使用字节级的回退 处理未知字符。最终词表大小为 256000 。



预训练配置：

使用了 384 个 DGX H100 节点，每个节点包括 8 个 Hopper 架构的 H100 80GB SXM5 GPU 。GPU 之间使用 NVLink 和 NVSwitch 连接，GPU 之间带宽为 900 GB/s。节点之间 使用 8 个 NVIDIA Mellanox 400 Gbps HDR InfiniBand HCA 进行节点间通信。

（……

训练时使用 8 路 张量并行和数据并行，还使用了分布式优化器将优化器状态分片到数据并行的副本上。随着 batch size 的增加，数据并行也从 96 增加到 384。

<img src="https://gqjia-images-1254146217.cos.ap-nanjing.myqcloud.com/gqjia-post202402271515393.png" alt="image-20240227151534355" style="zoom:50%;" />

训练耗时13天。

在 8T 数据预训练完成后，又做了继续预训练。数据包括两种，一种是之前数据中高质量的数据，一种是 benchmark-style alignment examples 。

（…….



zero-shot 下的  reasoning benchmarks 结果：

<img src="https://gqjia-images-1254146217.cos.ap-nanjing.myqcloud.com/gqjia-post202402271520323.png" alt="image-20240227152043296" style="zoom:50%;" />



BBH 和 MMLU上的效果：



<img src="https://gqjia-images-1254146217.cos.ap-nanjing.myqcloud.com/gqjia-post202402271522165.png" alt="image-20240227152246132" style="zoom:50%;" />



数学和代码上的效果：

<img src="https://gqjia-images-1254146217.cos.ap-nanjing.myqcloud.com/gqjia-post202402271524412.png" alt="image-20240227152408384" style="zoom:50%;" />



在多语言的两个任务上：

<img src="https://gqjia-images-1254146217.cos.ap-nanjing.myqcloud.com/gqjia-post202402271526445.png" alt="image-20240227152607411" style="zoom:50%;" />

<img src="https://gqjia-images-1254146217.cos.ap-nanjing.myqcloud.com/gqjia-post202402271526053.png" alt="image-20240227152619021" style="zoom:50%;" />



翻译任务：

<img src="https://gqjia-images-1254146217.cos.ap-nanjing.myqcloud.com/gqjia-post202402271526649.png" alt="image-20240227152643620" style="zoom:50%;" />



























